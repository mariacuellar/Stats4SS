<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Linear regression</title>

<script src="site_libs/header-attrs-2.10/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics for the Social Sciences (Crim 250)</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="EDA.html">EDA</a>
</li>
<li>
  <a href="Linear-regression.html">Linear regression</a>
</li>
<li>
  <a href="Assignments.html">Assignments</a>
</li>
<li>
  <a href="Slides.html">Slides</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Linear regression</h1>

</div>


<p>Created: 2021-10-19, Last compiled: 2021-12-09</p>
<p>Here we discuss how one should run a linear regression in R. There is a special emphasis on explaining what is a model, and how we use it to evaluate the relationship between two variables, x and y, in order to do proper inferences and predictions.</p>
<div id="lecture-6" class="section level1">
<h1>Lecture 6</h1>
<div id="what-is-linear-regression" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">What is linear regression?</h2>
<p>The correlation between two variables tells us whether the linear association between them is strong. But it does not tell us <em>what the line is</em>.</p>
<p>A linear model gives an equation of a straight line through the data. This model can predict the value y for any value x, which can be within the sample or not.</p>
<p>Of course, no line will go through all the points, but a linear model can summarize the general pattern with only a couple of parameters.</p>
<p>Like all models of the real world, the line will be wrong in the sense that it can’t match reality <em>exactly</em>, but it can help us understand how the variables are associated.</p>
</div>
<div id="predicted-values" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Predicted values</h2>
<p>The estimate made from a model is the <em>predicted value</em> and we write it as <span class="math inline">\(\hat{y}\)</span> (called <em>y-hat</em>) to distinguish it from the observed value, <em>y</em>.</p>
<p>The difference between the observed value and its associated predicted value is called the <em>residual</em>. The residual value tells us how far off the model’s prediction is at that point.</p>
<p><span class="math display">\[
Residual = Observed\ value - Predicted\ value.
\]</span></p>
<p><img src="images/residuals.png" /></p>
</div>
<div id="the-linear-model" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">The linear model</h2>
<p>A straight line can be written as <span class="math display">\[
y=mx + b.
\]</span></p>
<p>We’ll use this form for our linear model, but in statistics we use slightly different notation: <span class="math display">\[
\hat{y}= \hat{b}_0 + \hat{b}_1 x.
\]</span></p>
<p>We write <span class="math inline">\(\hat{y}\)</span> to emphasize that the points that satisfy this equation are just our <em>predicted</em> values, not the actual data values, which scatter around the line.</p>
<p>We write <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> for the slope and intercept of the line. The estimated <span class="math inline">\(\hat{b}\)</span>’s are called the <em>coefficients</em> of the linear model, <span class="math inline">\(b_1\)</span> is the slope which tells how rapidly <span class="math inline">\(\hat{y}\)</span> changes with respect to <span class="math inline">\(x\)</span>, and <span class="math inline">\(b_0\)</span> is the intercept, which tells where the line intercepts the <span class="math inline">\(y\)</span>-axis.</p>
</div>
<div id="interpretation" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Interpretation</h2>
<p>Suppose a model is: <span class="math display">\[
\widehat{Fat} = 8.4 + 0.91 Protein.
\]</span></p>
<p>This means the slope 0.91 says that an item with one more gram of protein can be expected, on average, to have 0,91 more grams of fat. For the intercept, even without protein, an item would have, on average, 8.4 grams of fat. Often the intercept won’t be meaningful, but it helps us position the model vertically.</p>
<p>This interpretation works for continuous (quantitative) predictor and outcome, but it’s not the same if either changes. More on this later.</p>
</div>
<div id="warning" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Warning</h2>
<p>This is where “correlation does not imply causation” becomes very important. It is not the same to say</p>
<p><strong>“If you increase protein by one gram, fat will increase by one gram,”</strong> as</p>
<p><strong>“For a higher protein, by one gram, fat is higher by one gram, on average.”</strong></p>
<p>(The second one is correct!) Why are these different?</p>
</div>
<div id="inference-vs.-prediction" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Inference vs. prediction</h2>
<p>Inference is about what is the relationship between x and y, and prediction is about if I saw a new x, what would the corresponding y for it be?</p>
</div>
<div id="recall-assumptions-of-linear-regression" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Recall: Assumptions of linear regression</h2>
<ol style="list-style-type: decimal">
<li><p><strong>Homoscedasticity</strong>: Homogeneity of variance. The size of the error in our prediction doesn’t change significantly across the values of the independent variable. i.e., The variance of residuals is the same for any value of <span class="math inline">\(x\)</span>.</p></li>
<li><p><strong>Independence between observations</strong>: the observations in the dataset were collected using statistically valid sampling methods, and there are no hidden relationships among observations.</p></li>
<li><p><strong>Normality</strong>: The data follows a normal distribution. i.e., For any fixed value of <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span> is normally distributed.</p></li>
<li><p><strong>Linearity</strong>: The relationship between the independent and dependent variable is linear: the line of best fit through the data points is a straight line (rather than a curve or some sort of grouping factor). i.e., The relationship between X and the mean of Y is linear.</p></li>
</ol>
</div>
<div id="visualizing-assumption-1-homoscedasticity" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Visualizing assumption 1: Homoscedasticity</h2>
<p>The assumption is that the data is homoscedastic.</p>
<p><img src="images/hetero.jpeg" /></p>
</div>
<div id="visualizing-assumption-2-independence-of-observations" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Visualizing assumption 2: Independence of observations</h2>
<p>We do not want connections like the ones in this social network:</p>
<p><img src="images/socialnetwork.jpeg" /></p>
</div>
<div id="visualizing-assumption-3-normality" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Visualizing assumption 3: Normality</h2>
<p><img src="images/normality.png" /></p>
</div>
<div id="visualizing-assumption-4-linearity" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Visualizing assumption 4: Linearity</h2>
<p>Actually, this is linearity, homoscedasticity, and normality.</p>
<p><img src="images/allassumptions.png" /></p>
</div>
<div id="diagnosic-plots" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Diagnosic plots</h2>
<p>Diagnosic plots are an amazing tool for checking whether your regression model is fitting well and satisfying assumptions.</p>
<p>We will study four of them that come with the <code>lm</code> function in R:</p>
<ul>
<li>Goodness of fit:
<ul>
<li>R-squared: Coefficient of determination</li>
<li>Residuals vs. fitted</li>
</ul></li>
<li>Assumption 1: Homoscedasticity
<ul>
<li>Scale-location</li>
</ul></li>
<li>Assumption 2: Independence
<ul>
<li>Can’t test visually</li>
</ul></li>
<li>Assumption 3: Normality
<ul>
<li>Normal Q-Q plot</li>
<li>Residuals vs. leverage</li>
</ul></li>
<li>Assumption 4: Linearity
<ul>
<li>No official plot, but could use a scatterplot.</li>
</ul></li>
</ul>
</div>
<div id="goodness-of-fit-coefficient-of-determination" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Goodness of fit: Coefficient of determination</h2>
<p>How can we tell if a linear model is fitting properly?</p>
<p>The <strong>coefficient of determination</strong> or <span class="math inline">\(R^2\)</span> is the variation accounted for by the model. <span class="math inline">\(R^2=1\)</span> means your model perfectly predicts the data, i.e., that all of the variance in the data is in the model. <span class="math inline">\(R^2=0\)</span> means your model is not a good fit for the data.</p>
<p><span class="math display">\[
R^2 = \frac{\text{Variance explained by the model}}{\text{Total variance}}.
\]</span> It is read as a percentage (i.e., has a value from 0 to 100%).</p>
<p>The <span class="math inline">\(R^2\)</span> on the left is 15% and the <span class="math inline">\(R^2\)</span> on the right is 85%.</p>
<p>When a regression model accounts for more of the variance, the data points are closer to the regression line. In practice, you’ll never see a regression model with an R2 of 100%.</p>
<p>Regression models with low R-squared values can be perfectly good models. Some fields of study have an inherently greater amount of unexplainable variation. In these areas, <span class="math inline">\(R^2\)</span> values are bound to be lower.</p>
<p><img src="images/rsquaredcomp.png" /></p>
</div>
<div id="scale-location-plot-a-way-to-test-assumption-1-homoscedasticity" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Scale-location plot: A way to test assumption 1 (homoscedasticity)</h2>
<p>It’s also called Spread-Location plot. This plot shows if residuals are spread equally along the ranges of predictors. This is how you can check the assumption of equal variance (homoscedasticity). It’s good if you see a horizontal line with equally (randomly) spread points.</p>
<p><img src="images/scalelocation.png" /></p>
</div>
<div id="residuals-vs.-fitted-plot-a-more-informative-version-of-r2" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Residuals vs. fitted plot: A more informative version of <span class="math inline">\(R^2\)</span></h2>
<p>We want to know how well the model fits, so we can ask instead what the model missed: the residuals. A scatterplot of the residuals vs. the <span class="math inline">\(x\)</span>-values should be the most boring scatterplot you’ve ever seen: It shouldn’t have any interesting features, like a direction, shape, or outliers (left figure).</p>
<p><img src="images/residualsvsfitted.png" /></p>
</div>
<div id="normal-q-q-plot-a-way-to-test-assumption-3-normality" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Normal Q-Q plot: A way to test assumption 3 (normality)</h2>
<p>This plot shows if residuals are normally distributed. Do residuals follow a straight line well or do they deviate severely? It’s good if residuals are lined well on the straight dashed line. What do you think? They are probably never a perfect straight line, and this will be your call. Case 2 below definitely concerns me. I would not be concerned by Case 1 too much, although an observation numbered as 38 looks a little off.</p>
<p><img src="images/normalqqplot.png" /></p>
</div>
<div id="residuals-vs.-leverage-plot-a-way-to-test-for-points-of-high-leverage" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Residuals vs. leverage plot: A way to test for points of high leverage</h2>
<p>This plot helps us to find influential cases, if there are any. Not all outliers are influential. Unlike the other plots, here patterns are not relevant. We watch out for outlying values at the upper right corner or at the lower right corner. Those spots are the places where cases can be influential for the model.</p>
<p>Look for cases outside of a dashed line, Cook’s distance. When cases are outside of the Cook’s distance (meaning they have high Cook’s distance scores), the cases are influential to the regression results. The regression results will be altered if we exclude those cases.</p>
<p><img src="images/residualsvsleverage.png" /></p>
</div>
<div id="residuals-vs.-leverage-plot" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Residuals vs. leverage plot</h2>
<p>Case 1 is the typical look when there is no influential case, or cases. You can barely see Cook’s distance lines (a red dashed line) because all cases are well inside of the Cook’s distance lines. In Case 2, a case is far beyond the Cook’s distance lines (the other residuals appear clustered on the left because the second plot is scaled to show larger area than the first plot). The plot identified the influential observation as #49. If I exclude the 49th case from the analysis, the slope coefficient changes from 2.14 to 2.68 and <span class="math inline">\(R^2\)</span> from .757 to .851. Pretty big impact!</p>
</div>
<div id="other-tools-to-improve-model-fit" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Other tools to improve model fit</h2>
<p>Your current model might not be the best way to understand your data. In that case, you may want to go back to the beginning. Is it really a linear relationship between the predictors and the outcome?</p>
<p>There are other tools we have not covered yet, which might make the model fit the data better:</p>
<ul>
<li>You may want to include a quadratic term, for example.</li>
<li>A log transformation may better represent the phenomena that you’d like to model.</li>
<li>Or, is there any important variable that you left out from your model? Other variables you didn’t include (e.g., age or gender) may play an important role in your model and data.</li>
<li>Or, maybe, your data were systematically biased when collecting data. You may want to redesign data collection methods.</li>
</ul>
</div>
<div id="example-simulated-height-and-weight-data" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Example: Simulated height and weight data</h2>
<pre class="r"><code>x &lt;- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
y &lt;- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
out &lt;- lm(y~x)
summary(out)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.3002 -1.6629  0.0412  1.8944  3.9775 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -38.45509    8.04901  -4.778  0.00139 ** 
## x             0.67461    0.05191  12.997 1.16e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.253 on 8 degrees of freedom
## Multiple R-squared:  0.9548, Adjusted R-squared:  0.9491 
## F-statistic: 168.9 on 1 and 8 DF,  p-value: 1.164e-06</code></pre>
</div>
<div id="diagnostic-plots" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">Diagnostic plots</h2>
<pre class="r"><code>par(mfrow=c(2,2))
summary(out)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.3002 -1.6629  0.0412  1.8944  3.9775 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -38.45509    8.04901  -4.778  0.00139 ** 
## x             0.67461    0.05191  12.997 1.16e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.253 on 8 degrees of freedom
## Multiple R-squared:  0.9548, Adjusted R-squared:  0.9491 
## F-statistic: 168.9 on 1 and 8 DF,  p-value: 1.164e-06</code></pre>
<pre class="r"><code>setwd(&quot;/Users/mariacuellar/Documents/Penn/Classes/Crim 250 - Statistics for the Social Sciences/Assignments/Assignment 2&quot;)

dat &lt;- read.csv(file = &#39;dat.nsduh.small.1.csv&#39;)

plot(dat$mjage, log(dat$cigage))</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>lm.out &lt;- lm(mjage~log(cigage), data=dat)</code></pre>
<pre class="r"><code>par(mfrow=c(2,2)) # Change the panel layout to 2 x 2
plot(lm.out)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-4-1.png" width="768" /></p>
</div>
</div>
<div id="lecture-11" class="section level1">
<h1>Lecture 11</h1>
<div id="example-cars" class="section level2">
<h2>Example: Cars</h2>
<p>We will be using an example from the <code>cars</code> dataset in R. This comes with R in the <code>datasets</code> package.</p>
<pre class="r"><code># install.packages(&quot;datasets&quot;) # only run this once per session!
library(datasets)</code></pre>
<p>The data give the speed of cars (in miles per hour, mph) and the distances taken to stop (in miles). The data were recorded in the 1920s.</p>
</div>
</div>
<div id="scatterplot" class="section level1">
<h1>(Scatterplot)</h1>
<p>This is what the scatterplot of speed vs distance looks like.</p>
<pre class="r"><code>library(datasets)
plot(cars$speed, cars$dist,  main=&quot;Relationship between Speed and Stopping Distance for 50 Cars&quot;,
    xlab=&quot;Speed in mph&quot;, ylab=&quot;Stopping Distance in feet&quot;)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>It kind of looks like there could be a linear relationship between the two variables, something like the blue line here. (Never mind how I plotted this blue line. I just included it here to show you that the line of best fit probably looks something like this blue line.)</p>
<pre class="r"><code>library(datasets)
reg.output.nc &lt;- lm(formula = dist ~ speed, data = cars)

plot(cars$speed, cars$dist,  main=&quot;Relationship between Speed and Stopping Distance for 50 Cars&quot;,
    xlab=&quot;Speed in mph&quot;, ylab=&quot;Stopping Distance in feet&quot;)
abline(reg.output.nc, col=&quot;blue&quot;)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>This blue line tells us there is a positive correlation between how fast the car is going and how far the car needs to go to stop. In fact, the correlation is</p>
<pre class="r"><code>cor(cars$speed, cars$dist)</code></pre>
<pre><code>## [1] 0.8068949</code></pre>
<p>So, the fact that the relationship looks linear tells us that perhaps a simple linear regression is a good model to fit to this dataset. That regression model will serve as a tool for us to be able to perform inferences (e.g. if I observe a higher stopping distance, is this associated with a higher speed? And if so by how much?) and make predictions (e.g. for a speed of 22 mph or 50 mph, neither of which are in the dataset, what is the estimated stopping distance?).</p>
</div>
<div id="linear-model" class="section level1">
<h1>Linear model</h1>
<div id="the-model" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">The model</h2>
<ul>
<li><p>The linear regression model assumes that the <em>means</em> of the distributions of y’s for each x fall along the line, even though the individuals are scattered around it.</p></li>
<li><p>The <strong>model</strong> is <span class="math display">\[
\mu_y = \beta_0 + \beta_1 x.
\]</span> We use Greek letters to denote idealized models. Whenever we use linear regression, we’re assuming that this is actually how the data points are distributed.</p></li>
<li><p>Are the data really going to be distributed like this?</p></li>
</ul>
</div>
<div id="the-errors" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">The errors</h2>
<ul>
<li><p>No, not all the individual y’s are at these means. Some are above, some below. So, like all models, this one makes <strong>errors</strong>. They are model errors so we call them <span class="math inline">\(\epsilon\)</span>.</p></li>
<li><p>When we include the errors, we can actually say that each individual y is along the line, with some variation, <span class="math display">\[y = \beta_0 + \beta_1 x + \epsilon,\]</span> where <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are each individual point’s <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> values, the <span class="math inline">\(\beta\)</span>s are the <strong>parameters</strong> of the model (slope and intercept), and <span class="math inline">\(\epsilon\)</span> are the model errors that soak up the deviation from the model to the actual point. This equation is true for each data point.</p></li>
</ul>
</div>
<div id="the-regression-line" class="section level2 unlisted unnumbered">
<h2 class="unlisted unnumbered">The regression line</h2>
<ul>
<li><p>We estimate the <span class="math inline">\(\beta\)</span>s by finding a <strong>regression line</strong> <span class="math display">\[\hat{y} = b_0 + b_1 x,\]</span> as in the previous class. The <strong>residuals</strong>, <span class="math inline">\(e=y-\hat{y}\)</span> are the sample-based versions of the errors <span class="math inline">\(\epsilon\)</span>.</p></li>
<li><p>We use a method called <strong>least squares regression</strong>, which minimizes the vertical distance from the data points to the regression line (the sum of the squares of the residuals), to get reasonable estimates of the parameters of this model from a random sample of data.</p></li>
<li><p><strong>Important note</strong>: We don’t expect the assumptions to be exactly true, and we know that all models are wrong, but the linear model is often close enough to be very useful.</p></li>
</ul>
</div>
</div>
<div id="procedure-for-linear-regression" class="section level1">
<h1>Procedure for linear regression</h1>
<p>So, we have an idealized model that we’re going to use to see if there are interesting relationships between our variables. But, we’re not sure it’s the right model to use. Should we just go ahead and use it even if it’s the wrong model, and then later see if it worked? Doesn’t that seem dishonest? How can we use the model and the diagnostics properly?</p>
<p>We have some visual tests we can use before running the regression (does the scatterplot of y vs. x data look like it’s distributed like a line?) and diagnostics that we can use after running the regression. We’ll use these tools in the right order to run a linear model.</p>
<p>The following is a reasonable procedure from DVB. Note that although this seems like a simple algorithm, it’s not always the right thing to do. Remember this is statistics: you need a human deciding whether the assumptions you are making are too strong, and whether the diagnostics you’re checking look good enough. That’s why we go over the assumptions and the diagnostics later on. On a test, you should be able to respond to questions about whether you think each of the four assumptions is satisfied.</p>
<p><img src="images/Procedure%20for%20regression.png" /></p>
</div>
<div id="r-linear-regression-formula-and-output" class="section level1">
<h1>R linear regression formula and output</h1>
<p>Note: We are going to use a trick here called scaling the data. All this does is give us an easier time interpreting the y-intercept. You do not need to scale the data in most cases.</p>
<pre class="r"><code>cars$speed.c = scale(cars$speed, center=TRUE, scale=FALSE) # scaling the data
reg.output &lt;- lm(formula = dist ~ speed.c, data = cars) # running regression
summary(reg.output) # calling the summary of the fitted model</code></pre>
<pre><code>## 
## Call:
## lm(formula = dist ~ speed.c, data = cars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.069  -9.525  -2.272   9.215  43.201 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  42.9800     2.1750  19.761  &lt; 2e-16 ***
## speed.c       3.9324     0.4155   9.464 1.49e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15.38 on 48 degrees of freedom
## Multiple R-squared:  0.6511, Adjusted R-squared:  0.6438 
## F-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12</code></pre>
<p>The model above is achieved by using the <code>lm()</code> function in R and the output is called using the <code>summary()</code> function on the model. [Cite: Felipe Rego.]</p>
<ul>
<li><p><strong>Formula call</strong>: The first item shown in the output is the formula R used to fit the data. Note the simplicity in the syntax: the formula just needs the predictor (x) and the target/response variable (y), together with the data being used (dat).</p></li>
<li><p><strong>Residuals</strong>: The next item in the model output talks about the residuals. Residuals are essentially the difference between the actual observed response values (distance to stop dist in our case) and the response values that the model predicted.</p></li>
<li><p><strong>Coefficient - Estimate</strong>: The coefficient Estimate contains two rows; the first one is the intercept. The intercept, in our example, is essentially the expected value of the distance required for a car to stop when we consider the average speed of all cars in the dataset. In other words, it takes an average car in our dataset 42.98 feet to come to a stop. The second row in the Coefficients is the slope, or in our example, the effect speed has in distance required for a car to stop. The slope term in our model is saying that for every 1 mph increase in the speed of a car, the required distance to stop goes up by 3.9324088 feet. NOTE: This is not a causal interpretation. Just make sure you say that a higher value of speed is associated with higher values of distance, by this much, but don’t say that if you increase one the other one will increase.</p></li>
<li><p><strong>Coefficient - Standard Error</strong>: The coefficient Standard Error measures the average amount that the coefficient estimates vary from the actual average value of our response variable. We’d ideally want a lower number relative to its coefficients. In our example, we’ve previously determined that for every 1 mph increase in the speed of a car, the required distance to stop goes up by 3.9324088 feet. The Standard Error can be used to compute an estimate of the expected difference in case we ran the model again and again. In other words, we can say that the required distance for a car to stop can vary by 0.4155128 feet. The Standard Errors can also be used to compute confidence intervals and to statistically test the hypothesis of the existence of a relationship between speed and distance required to stop.</p></li>
<li><p><strong>Coefficient - t-value</strong>: The coefficient t-value is a measure of how many standard deviations our coefficient estimate is far away from 0. We want it to be far away from zero as this would indicate we could reject the null hypothesis - that is, we could declare a relationship between speed and distance exist. In our example, the t-statistic values are relatively far away from zero and are large relative to the standard error, which could indicate a relationship exists. In general, t-values are also used to compute p-values.</p></li>
<li><p><strong>Coefficient - Pr(&gt;t)</strong>: The Pr(&gt;t) acronym found in the model output relates to the probability of observing any value equal or larger than t. A small p-value indicates that it is unlikely we will observe a relationship between the predictor (speed) and response (dist) variables due to chance. Typically, a p-value of 5% or less is a good cut-off point. In our model example, the p-values are very close to zero. Note the ‘signif. Codes’ associated to each estimate. Three stars (or asterisks) represent a highly significant p-value. Consequently, a small p-value for the intercept and the slope indicates that we can reject the null hypothesis which allows us to conclude that there is a relationship between speed and distance.</p></li>
<li><p><strong>Residual Standard Error</strong>: Residual Standard Error is measure of the quality of a linear regression fit. Theoretically, every linear model is assumed to contain an error term E. Due to the presence of this error term, we are not capable of perfectly predicting our response variable (dist) from the predictor (speed) one. The Residual Standard Error is the average amount that the response (dist) will deviate from the true regression line. In our example, the actual distance required to stop can deviate from the true regression line by approximately 15.3795867 feet, on average. In other words, given that the mean distance for all cars to stop is 42.98 and that the Residual Standard Error is 15.3795867, we can say that the percentage error is (any prediction would still be off by) 35.78%. It’s also worth noting that the Residual Standard Error was calculated with 48 degrees of freedom. Simplistically, degrees of freedom are the number of data points that went into the estimation of the parameters used after taking into account these parameters (restriction). In our case, we had 50 data points and two parameters (intercept and slope).</p></li>
<li><p><strong>Multiple R-squared, Adjusted R-squared</strong>: The R-squared (R2) statistic provides a measure of how well the model is fitting the actual data. It takes the form of a proportion of variance. R2 is a measure of the linear relationship between our predictor variable (speed) and our response / target variable (dist). It always lies between 0 and 1 (i.e.: a number near 0 represents a regression that does not explain the variance in the response variable well and a number close to 1 does explain the observed variance in the response variable). In our example, the R2 we get is 0.6510794. Or roughly 65% of the variance found in the response variable (dist) can be explained by the predictor variable (speed). Step back and think: If you were able to choose any metric to predict distance required for a car to stop, would speed be one and would it be an important one that could help explain how distance would vary based on speed? I guess it’s easy to see that the answer would almost certainly be a yes. That why we get a relatively strong R2. Nevertheless, it’s hard to define what level of R2 is appropriate to claim the model fits well. Essentially, it will vary with the application and the domain studied.</p></li>
<li><p>A side note: In multiple regression settings, the R2 will always increase as more variables are included in the model. That’s why the adjusted R2 is the preferred measure as it adjusts for the number of variables considered.</p></li>
<li><p><strong>F-Statistic</strong>: F-statistic is a good indicator of whether there is a relationship between our predictor and the response variables. The further the F-statistic is from 1 the better it is. However, how much larger the F-statistic needs to be depends on both the number of data points and the number of predictors. Generally, when the number of data points is large, an F-statistic that is only a little bit larger than 1 is already sufficient to reject the null hypothesis (H0 : There is no relationship between speed and distance). The reverse is true as if the number of data points is small, a large F-statistic is required to be able to ascertain that there may be a relationship between predictor and response variables. In our example the F-statistic is 89.5671065 which is relatively larger than 1 given the size of our data.</p></li>
</ul>
<p>Now we revisit the assumptions.</p>
</div>
<div id="linearity-assumption" class="section level1">
<h1>1. Linearity assumption</h1>
<ul>
<li><p>This is satisfied if a scatterplot of x and y looks straight. If the true relationship between x and y is far from linear and we use a straight line to fit the data, our entire analysis will be useless, so we always check this first.</p></li>
<li><p><strong>How to check?</strong> You can see violations of this if you plot a scatterplot of the residuals against x or against the predicted values <span class="math inline">\(\hat{y}\)</span>. That plot will have a horizontal direction and should have no pattern if the condition is satisfied. You can think of the residuals as being estimates of the error terms. So anytime we’re looking at a plot that involves residuals, we’re doing so because we’re trying to assess whether some assumption about the errors appears to hold in our data.</p></li>
</ul>
</div>
<div id="residuals-vs.-x" class="section level1">
<h1>(Residuals vs. x)</h1>
<pre class="r"><code>plot(cars$speed.c, reg.output$residuals, ylim=c(-15,15), main=&quot;Residuals vs. x&quot;, xlab=&quot;x, Scaled speed&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="residuals-vs.-fitted" class="section level1">
<h1>(Residuals vs. fitted)</h1>
<pre class="r"><code>plot(reg.output, which=1)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-11-1.png" width="480" /></p>
<ul>
<li>Looking at the Residuals vs Fitted plot (showing residuals on the y-axis and fitted y’s on the x-axis), we see that the red line (which is just a scatterplot smoother, showing the average value of the residuals at each value of fitted value) is quite flat. This tells us that there is no discernible non-linear trend to the residuals. Furthermore, the residuals appear to be equally variable across the entire range of fitted values. There is no indication of non-constant variance.</li>
</ul>
</div>
<div id="independence-assumption" class="section level1">
<h1>2. Independence assumption</h1>
<ul>
<li><p>The errors in the true underlying regression model (the <span class="math inline">\(\epsilon\)</span>s) must be independent of each other. There is no way to check this is true. We check displays of the regression residuals for evidence of patterns, trends, or clumping, any of which would suggest a failure of independence. e.g. For time series, the error our model makes today may be similar to the one it made for yesterday.</p></li>
<li><p><strong>How to check?</strong> You can see violations of this by plotting the residuals against x and looking for patterns (see plot above). Or, plot the residuals vs. the residuals offset or lagged by one time position. Neither plot should show patterns.</p></li>
<li><p>In our example this looks pretty good. We don’t need to plot the residuals vs. the lagged residuals because we don’t think there’s a time-series component in the data.</p></li>
</ul>
</div>
<div id="equal-variance-assumptionhomoscedasticity" class="section level1">
<h1>3. Equal variance assumption/homoscedasticity</h1>
<ul>
<li><p>The variability in y should be about the same for all values of x. The standard deviation of the residuals “pools” information across all of the individual distributions at each x-value, and pooled estimates are appropriate only when they combine information for groups with the same variance.</p></li>
<li><p><strong>How to check?</strong> A scatterplot of y against x offers a visual check (we did this all the way at the top). Be alert for a “fan” shape or other tendency for the variation to grow or shrink in one part of the scatterplot. Often, it is better to look at the residuals plotted against the predicted values <span class="math inline">\(\hat{y}\)</span>.</p></li>
</ul>
</div>
<div id="scale-location-plot" class="section level1">
<h1>(Scale-location plot)</h1>
<pre class="r"><code>plot(reg.output, which=3)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-12-1.png" width="480" /></p>
<ul>
<li><p>The scale-location plot is a more sensitive approach to looking for deviations from the constant variance assumption. If you see significant trends in the red line on this plot, it tells you that the residuals (and hence errors) have non-constant variance. That is, the assumption that all the errors have the same variance is not true.</p></li>
<li><p>When you see a flat line like what’s shown above, it means your errors have constant variance, like we want to see.</p></li>
</ul>
</div>
<div id="normal-population-assumption" class="section level1">
<h1>4. Normal population assumption</h1>
<ul>
<li><p>We assume the errors around the idealized regression line at each value of x follow a Normal model. <strong>Why?</strong> We need this assumption so we can use Student’s t-model for inference.</p></li>
<li><p>This assumption becomes less important as the same size grows because the model is about means and the Central Limit Theorem takes over.</p></li>
<li><p><strong>How to check?</strong> Nearly normal condition (qq plot) and outlier condition (Cook’s distance).</p></li>
</ul>
</div>
<div id="residuals-vs.-leverage-plot-1" class="section level1">
<h1>(Residuals vs. Leverage plot)</h1>
<pre class="r"><code>plot(reg.output, which=5)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-13-1.png" width="480" /></p>
<ul>
<li>There’s no single accepted definition for what consitutes an outlier. One possible definition is that an outlier is any point that isn’t approximated well by the model (has a large residual) and which significantly influences model fit (has large leverage). This is where the Residuals vs Leverage plot comes in.</li>
</ul>
</div>
<div id="normal-qq-plot" class="section level1">
<h1>(Normal qq plot)</h1>
<pre class="r"><code>plot(reg.output, which=2)</code></pre>
<p><img src="Linear-regression_files/figure-html/unnamed-chunk-14-1.png" width="480" /></p>
<ul>
<li><p>The Normal QQ plot helps us to assess whether the residuals are roughly normally distributed. If the residuals look far from normal we may be in trouble. In particular, if the residual tend to be larger in magnitude than what we would expect from the normal distribution, then our p-values and confidence intervals may be too optimisitic. i.e., we may fail to adequately account for the full variability of the data.</p></li>
<li><p>This qq plot is not great, especially at the top right. This tells us that the right tail of the distribution is probably “light” or smaller than usual for a normal distribution.</p></li>
<li><p>The images below are a guide that tells you what might be happening.</p></li>
</ul>
<p><img src="images/qqplot%20interpretations.png" /></p>
</div>
<div id="references" class="section level1 unlisted unnumbered">
<h1 class="unlisted unnumbered">References</h1>
<ul>
<li><p>DVB Chp 25</p></li>
<li><p><a href="https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R" class="uri">https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R</a></p></li>
<li><p><a href="https://www.andrew.cmu.edu/user/achoulde/94842/homework/regression_diagnostics.html" class="uri">https://www.andrew.cmu.edu/user/achoulde/94842/homework/regression_diagnostics.html</a></p></li>
<li><p><a href="https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot" class="uri">https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot</a></p></li>
<li><p><a href="https://data.library.virginia.edu/diagnostic-plots/" class="uri">https://data.library.virginia.edu/diagnostic-plots/</a></p></li>
</ul>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
